# languageModels
2- and 3-gram language models with Kneser-Ney &amp; Good Turing smoothing for improved performance.
</br>

Perplexity has also been calculated for all 4 combinations of models & smoothing techniques.
